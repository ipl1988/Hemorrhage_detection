{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b594337c-53d5-449d-891a-3a76bb063e61",
   "metadata": {},
   "source": [
    "# Bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c29d932-02ff-4287-ba9d-31607f17f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Windowing for bone tissue\n",
    "window_center = 700\n",
    "window_width = 3200\n",
    "min_val = window_center - (window_width / 2)\n",
    "max_val = window_center + (window_width / 2)\n",
    "windowed_image_bone = np.clip(ds.pixel_array, min_val, max_val)\n",
    "\n",
    "# Step 2: Normalize\n",
    "normalized_image_bone = (windowed_image_bone - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7525d69a-71a5-4824-b3f6-74b53fe89101",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(normalized_image_bone, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(normalized_image_bone, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf3e265-d18e-4c25-b9ce-4f2d1e6cdb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(normalized_image_bone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df325201-8085-4d22-8fb4-9a65b379ecca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_image_brain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming image_data is your 512x512 tomographic image (e.g., CT or MRI scan)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Kernel size of 5x5 image to camtpure local features, reduce the number of trainable parameters\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m image_data_brain \u001b[38;5;241m=\u001b[39m\u001b[43mnormalized_image_brain\u001b[49m  \u001b[38;5;66;03m# Replace with actual image data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 1. Create the 5x5 Averaging Kernel\u001b[39;00m\n\u001b[1;32m      6\u001b[0m kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalized_image_brain' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming image_data is your 512x512 tomographic image (e.g., CT or MRI scan)\n",
    "# Kernel size of 5x5 image to camtpure local features, reduce the number of trainable parameters\n",
    "image_data_brain =normalized_image_brain  # Replace with actual image data\n",
    "\n",
    "# 1. Create the 5x5 Averaging Kernel\n",
    "kernel_size = 5\n",
    "avg_kernel = np.ones((kernel_size, kernel_size)) / (kernel_size * kernel_size)\n",
    "\n",
    "# 2. Apply the kernel using convolution\n",
    "smoothed_image = convolve(image_data_brain, avg_kernel)\n",
    "\n",
    "# 3. Display the original and smoothed images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "ax[0].imshow(image_data_brain, cmap='gray')\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Smoothed image\n",
    "ax[1].imshow(smoothed_image, cmap='gray')\n",
    "ax[1].set_title(\"Smoothed Image (Averaging Kernel)\")\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a7912-97a8-41ae-9b04-e025e275434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator --> ImageDataGenerator for real-time augmentation and batching\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data generators for augmentation\n",
    "train_datagen = ImageDataGenerator(rotation_range=10,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "val_datagen= ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Load data from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/juliaojedaalonso/Dropbox/Intracraneal hemorrhage detection project/train_data',\n",
    "    target_size=(512,512),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator= val_datagen.flow_from_directory(\n",
    "    '/Users/juliaojedaalonso/Dropbox/Intracraneal hemorrhage detection project/val_data',\n",
    "    target_size=(512,512),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed854ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/Users/juliaojedaalonso/Dropbox/Intracraneal hemorrhage detection project/test_data',\n",
    "    target_size=(512,512),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths to images and corresponding labels\n",
    "image_paths = [' .jpg',' .jpg',' .jpg',' .jpg',' .jpg',' .jpg']\n",
    "labels = [0,1,2,3,4,5] # 0 = label, 2 = label, 3 = label, 4 = label, 5 = label\n",
    "\n",
    "#Define a function to load and preprocess images\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=1) \n",
    "    image = tf.image.resize(image, [256,256])\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "# Create a tf.data.Dataset from image paths and labels\n",
    "dataset = dataset.map (lambda path, label: (load_and_preprocess_image(path), label))\n",
    "\n",
    "# Batch the dataset for training\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "# Iterate through the dataset\n",
    "for images, labels in dataset:\n",
    "    print(\"Batch of labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba585a1",
   "metadata": {},
   "source": [
    "# Dataset for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b3e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data location\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    seed='None',\n",
    "    image_size=(512,512),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Test data location\n",
    "val_ds = image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    seed='None',\n",
    "    image_size=(512,512),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e966d3ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'get_testdata_file' does not support absolute paths, as it only works with internal pydicom test data - did you mean 'dcmread(\"/Users/juliaojedaalonso/Dropbox/Intracraneal hemorrhage detection project/download_dataset_100/stage_2_train/ID_0a0f3abd0.dcm\")'?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydicom\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_testdata_file\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load a DICOM file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_testdata_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/juliaojedaalonso/Dropbox/Intracraneal hemorrhage detection project/download_dataset_100/stage_2_train/ID_0a0f3abd0.dcm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m dicom \u001b[38;5;241m=\u001b[39m pydicom\u001b[38;5;241m.\u001b[39mdcmread(file_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Access metadata\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pydicom/data/data_manager.py:332\u001b[0m, in \u001b[0;36mget_testdata_file\u001b[0;34m(name, read, download)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m\"\"\"Return an absolute path to the first matching dataset with filename\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m`name` that is found in a local or external pydicom datastore.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m    If `name` is an absolute path.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misabs(name):\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_testdata_file\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not support absolute paths, as it only works\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with internal pydicom test data - did you mean \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdcmread(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m     )\n\u001b[1;32m    337\u001b[0m path \u001b[38;5;241m=\u001b[39m _get_testdata_file(name\u001b[38;5;241m=\u001b[39mname, download\u001b[38;5;241m=\u001b[39mdownload)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mand\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: 'get_testdata_file' does not support absolute paths, as it only works with internal pydicom test data - did you mean 'dcmread(\"/Users/juliaojedaalonso/Dropbox/Intracraneal hemorrhage detection project/download_dataset_100/stage_2_train/ID_0a0f3abd0.dcm\")'?"
     ]
    }
   ],
   "source": [
    "import pydicom\n",
    "from pydicom.data import get_testdata_file\n",
    "\n",
    "# Load a DICOM file\n",
    "file_path = get_testdata_file(\"/Users/juliaojedaalonso/Dropbox/Intracraneal hemorrhage detection project/download_dataset_100/stage_2_train/ID_0a0f3abd0.dcm\")\n",
    "dicom = pydicom.dcmread(file_path)\n",
    "\n",
    "# Access metadata\n",
    "print(dicom.PatientName)\n",
    "print(dicom.Modality)\n",
    "\n",
    "# Access pixel data\n",
    "pixel_array = dicom.pixel_array\n",
    "print(pixel_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec9d363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac9215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
